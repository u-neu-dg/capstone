{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "In my capstone project I will revisit the server log data of the platform *Sci-Hub* used by John Bohannon for his analysis of Sci-Hub user behaviour published in Science Magazine 2016 (https://www.sciencemag.org/news/2016/04/whos-downloading-pirated-papers-everyone). Sci-Hub is a shadow library website that provides free access to millions of research papers and books, without regard to copyright, by bypassing publishers' paywalls in various ways. (https://en.wikipedia.org/wiki/Sci-Hub).\n",
    "The dataset Bohannon was provided by the Sci-Hub owner covers logs from September 2015 to February 2016 and has 28 million log entries.\n",
    "\n",
    "Using the *March 2020 Public Data File from Crossref*, provided by Crossref on Academic Torrents https://academictorrents.com/details/0c6c3fbfdc13f0169b561d29354ea8b188eb9d63 which includes metadata of 112 million research articles, and mapping it to the Sci-Hub data, I will provide even more explorative options and insights into the behaviour and preferences of Sci-Hub users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project\n",
    "\n",
    "After cleaning the data from the two sources, Sci-Hub and Crossref using the `pandas`library, I will stage the data from both sources in S3. Using a data warehouse in the form of a star schema relational database in Redshift I am going to make the data accessible for analyses via SQL or other suitable tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Describe and Gather Data, Explore, Clean and Save: Sci-Hub\n",
    "\n",
    "The Sci-Hub data consists of 6 text files, one for each month, which are tab-separated:\n",
    "\n",
    "`sep2015.tab, \n",
    "oct2015.tab, \n",
    "nov2015.tab, \n",
    "dec2015.tab, \n",
    "jan2016.tab, \n",
    "feb2016.tab`\n",
    "\n",
    "There are 6 columns of data available, each row is a reference to a download of an article (referenced via the DOI) by a certain user which has further location details.\n",
    "No column names are provided. I am using `dec2015.tab` in the `scihub_data_raw` folder for an exploration with the `pandas` library.\n",
    "\n",
    "**Please download the sample files from https://drive.google.com/drive/folders/1CZyJoLvhWpWSUbNGSuBIUBLY9YBWCPgg?usp=sharing\n",
    "and add them to a `scihub_data_raw` folder in the project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = \"scihub_data_raw/dec2015.tab\"\n",
    "\n",
    "df_scihub = pd.read_table(path,names=[\"timestamp\", \"doi\", \"user_id\", \"user_country\", \"user_city\", \"user_location\"],encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual content of each of the columns suggests the following schema with column names `timestamp, doi, user_id, user_country, user_city, user_location`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>doi</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_country</th>\n",
       "      <th>user_city</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-01 00:00:00</td>\n",
       "      <td>10.1080/00423110701422426</td>\n",
       "      <td>56ed2c3981074</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>24.7135517,46.6752957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-01 00:00:03</td>\n",
       "      <td>10.1111/j.1365-2222.2010.03601.x</td>\n",
       "      <td>56ed2b55bf5b4</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Solnechnoye</td>\n",
       "      <td>60.1516625,29.9345185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-01 00:00:04</td>\n",
       "      <td>10.1007/978-1-4684-0274-2</td>\n",
       "      <td>56ed2b36d7d70</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Ponte Ronca</td>\n",
       "      <td>44.5017279,11.1891377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-01 00:00:04</td>\n",
       "      <td>10.1016/j.ejor.2003.11.032</td>\n",
       "      <td>56ed2c3981124</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>Budapest</td>\n",
       "      <td>47.497912,19.040235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-01 00:00:05</td>\n",
       "      <td>10.1049/iet-cdt.2014.0146</td>\n",
       "      <td>56ed9ff1c5403</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Tehran</td>\n",
       "      <td>35.6891975,51.3889736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                               doi        user_id  \\\n",
       "0  2015-12-01 00:00:00         10.1080/00423110701422426  56ed2c3981074   \n",
       "1  2015-12-01 00:00:03  10.1111/j.1365-2222.2010.03601.x  56ed2b55bf5b4   \n",
       "2  2015-12-01 00:00:04         10.1007/978-1-4684-0274-2  56ed2b36d7d70   \n",
       "3  2015-12-01 00:00:04        10.1016/j.ejor.2003.11.032  56ed2c3981124   \n",
       "4  2015-12-01 00:00:05         10.1049/iet-cdt.2014.0146  56ed9ff1c5403   \n",
       "\n",
       "   user_country    user_city          user_location  \n",
       "0  Saudi Arabia       Riyadh  24.7135517,46.6752957  \n",
       "1        Russia  Solnechnoye  60.1516625,29.9345185  \n",
       "2         Italy  Ponte Ronca  44.5017279,11.1891377  \n",
       "3       Hungary     Budapest    47.497912,19.040235  \n",
       "4          Iran       Tehran  35.6891975,51.3889736  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scihub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`timestamp`, `doi`, and `user_id` seem to be available for almost all rows. `user_country`, `user_country` ànd`user_location` are not provided for all downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp             1\n",
       "doi                   2\n",
       "user_id               1\n",
       "user_country      86058\n",
       "user_city        748116\n",
       "user_location     86058\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scihub.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `clean_scihub_data` performs the data cleaning as described in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_scihub_data(df_scihub):\n",
    "    \"\"\"\n",
    "    cleans the data of the Sci-Hub files\n",
    "    requires a dataframe as input\n",
    "    creates the 'day' column for partitioning\n",
    "    removes rows with empty data in columns timestamp, doi and user_id\n",
    "    \"\"\"\n",
    "    df_scihub[\"day\"] = pd.to_datetime(df_scihub[\"timestamp\"]).dt.day\n",
    "    df_scihub[\"timestamp\"] = pd.to_datetime(df_scihub[\"timestamp\"])\n",
    "    df_scihub = df_scihub[~df_scihub[\"timestamp\"].isnull()]\n",
    "    df_scihub = df_scihub[~df_scihub[\"doi\"].isnull()]\n",
    "    df_scihub = df_scihub[~df_scihub[\"user_id\"].isnull()]\n",
    "    df_scihub[\"day\"] = df_scihub[\"day\"].astype(int)\n",
    "    return df_scihub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean all files in `scihub_data_raw` (samples in the folder: `dec2015.tab` and `jan2016.tab`) and save them in the `scihub_data`folder in parquet format, partitioned by `day`, I am using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading scihub_data_raw/jan2016.tab\n",
      "saved scihub_data/jan2016.parquet\n",
      "loading scihub_data_raw/dec2015.tab\n",
      "saved scihub_data/dec2015.parquet\n"
     ]
    }
   ],
   "source": [
    "path = \"scihub_data_raw/\"\n",
    "\n",
    "filenames=glob.glob(os.path.join(path, '*.tab'))\n",
    "for filename in filenames:\n",
    "    print(\"loading {}\".format(filename))\n",
    "    \n",
    "    df = pd.read_table(filename,names=[\"timestamp\", \"doi\", \"user_id\", \"user_country\", \"user_city\", \"user_location\"],encoding=\"UTF-8\")\n",
    "    \n",
    "    df = clean_scihub_data(df)\n",
    "    new_filename = filename.replace(\"_raw\",\"\").replace(\".tab\",\".parquet\")\n",
    "    df.to_parquet(new_filename, partition_cols=[\"day\"], engine='pyarrow')\n",
    "    print(\"saved {}\".format(new_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I uploaded these files manually to S3 bucket `s3://scihub-data/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Describe and Gather Data, Explore, Clean and Save: Crossref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crossref data includes metadata for each DOI registered at Crossref. The file format is JSON, there are 37000 single files.\n",
    "I will look at one file, `0.json.gz` to analyse the data structure locally. In the project folder `crossref_data_raw` I saved 33 sample files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"crossref_data_raw/0.json.gz\"\n",
    "with gzip.open(path) as file:\n",
    "    json_object = json.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the JSON object in each file contains a list of `items`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"items\": [{\"indexed\": {\"date-parts\": [[2019, 11, 19]], \"date-time\": \"2019-11-19T17:15:40Z\", \"timestamp\": 1574183740979}, \"reference-count\": 0, \"publisher\": \"American Medical Association (AMA)\", \"issue\": \"4\", \"content-domain\": {\"domain\": [], \"crossmark-restriction\": false}, \"short-container-title\": '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(json_object)[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and there are 3000 items in  each of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_object[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one item is a nested JSON with a large amount of metadata, but for our purpose we will not need all of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexed': {'date-parts': [[2019, 11, 19]],\n",
       "  'date-time': '2019-11-19T17:15:40Z',\n",
       "  'timestamp': 1574183740979},\n",
       " 'reference-count': 0,\n",
       " 'publisher': 'American Medical Association (AMA)',\n",
       " 'issue': '4',\n",
       " 'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       " 'short-container-title': ['Archives of Internal Medicine'],\n",
       " 'published-print': {'date-parts': [[2006, 2, 27]]},\n",
       " 'DOI': '10.1001/.389',\n",
       " 'type': 'journal-article',\n",
       " 'created': {'date-parts': [[2006, 2, 27]],\n",
       "  'date-time': '2006-02-27T21:28:23Z',\n",
       "  'timestamp': 1141075703000},\n",
       " 'page': '389-390',\n",
       " 'source': 'Crossref',\n",
       " 'is-referenced-by-count': 0,\n",
       " 'title': ['Decision Making at the Fringe of Evidence: Take What You Can Get'],\n",
       " 'prefix': '10.1001',\n",
       " 'volume': '166',\n",
       " 'author': [{'given': 'N. F.', 'family': 'Col', 'affiliation': []}],\n",
       " 'member': '10',\n",
       " 'container-title': ['Archives of Internal Medicine'],\n",
       " 'original-title': [],\n",
       " 'deposited': {'date-parts': [[2007, 2, 13]],\n",
       "  'date-time': '2007-02-13T20:56:13Z',\n",
       "  'timestamp': 1171400173000},\n",
       " 'score': None,\n",
       " 'subtitle': [],\n",
       " 'short-title': [],\n",
       " 'issued': {'date-parts': [[2006, 2, 27]]},\n",
       " 'references-count': 0,\n",
       " 'URL': 'http://dx.doi.org/10.1001/.389',\n",
       " 'relation': {},\n",
       " 'ISSN': ['0003-9926'],\n",
       " 'issn-type': [{'value': '0003-9926', 'type': 'print'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_object[\"items\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to extract the columns `\"doi\", \"type\", \"title\", \"published-print\", \"prefix\", \"publisher\", \"subject\"` including some data cleaning as described in the docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_crossref_data(json_object):\n",
    "    \"\"\"\n",
    "    extracts the items of the Crossref file\n",
    "    flattens the JSON\n",
    "    extracts columns:\n",
    "    \"doi\", \"type\", \"title\", \"published-print\", \"prefix\", \"publisher\", \"subject\"\n",
    "    remove all rows where \"doi\" is null\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(json_object[\"items\"])\n",
    "    df = pd.json_normalize(json_object[\"items\"])\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df[\"title\"]=df[\"title\"].str[0]\n",
    "    df[\"published-print\"]=df[\"published-print.date-parts\"].astype(str).str.extract(r'(\\d{4})')\n",
    "    if \"subject\" in df.columns:\n",
    "        df[\"subject\"]=df[\"subject\"].str[0]\n",
    "    else:\n",
    "        df[\"subject\"]=np.nan\n",
    "    df=df[~df[\"doi\"].isnull()]\n",
    "\n",
    "    return df[[\"doi\", \"type\", \"title\", \"published-print\", \"prefix\", \"publisher\", \"subject\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>published-print</th>\n",
       "      <th>prefix</th>\n",
       "      <th>publisher</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1001/.389</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Decision Making at the Fringe of Evidence: Tak...</td>\n",
       "      <td>2006</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1001/.391</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Treatment of Excessive Anticoagulation With Ph...</td>\n",
       "      <td>2006</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1001/.405</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Neutropenia in Human Immunodeficiency Virus In...</td>\n",
       "      <td>2006</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1001/.411</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Cocoa Intake, Blood Pressure, and Cardiovascul...</td>\n",
       "      <td>2006</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1001/.424</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Effect of Cholecalciferol Plus Calcium on Fall...</td>\n",
       "      <td>2006</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>10.1001/archderm.111.9.1135</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Toxic epidermal necrolysis. A review of 75 cas...</td>\n",
       "      <td>1975</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>10.1001/archderm.111.9.1140</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Complement component analysis in angiodema. Di...</td>\n",
       "      <td>1975</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>10.1001/archderm.111.9.1143</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Treatment of corns by injectable silicone</td>\n",
       "      <td>1975</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>10.1001/archderm.111.9.1146</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Hairy cutaneous malformations of palms and sol...</td>\n",
       "      <td>1975</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>10.1001/archderm.111.9.1150</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Immunocytochemical localization of cathepsin D...</td>\n",
       "      <td>1975</td>\n",
       "      <td>10.1001</td>\n",
       "      <td>American Medical Association (AMA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              doi             type  \\\n",
       "0                    10.1001/.389  journal-article   \n",
       "1                    10.1001/.391  journal-article   \n",
       "2                    10.1001/.405  journal-article   \n",
       "3                    10.1001/.411  journal-article   \n",
       "4                    10.1001/.424  journal-article   \n",
       "...                           ...              ...   \n",
       "2995  10.1001/archderm.111.9.1135  journal-article   \n",
       "2996  10.1001/archderm.111.9.1140  journal-article   \n",
       "2997  10.1001/archderm.111.9.1143  journal-article   \n",
       "2998  10.1001/archderm.111.9.1146  journal-article   \n",
       "2999  10.1001/archderm.111.9.1150  journal-article   \n",
       "\n",
       "                                                  title published-print  \\\n",
       "0     Decision Making at the Fringe of Evidence: Tak...            2006   \n",
       "1     Treatment of Excessive Anticoagulation With Ph...            2006   \n",
       "2     Neutropenia in Human Immunodeficiency Virus In...            2006   \n",
       "3     Cocoa Intake, Blood Pressure, and Cardiovascul...            2006   \n",
       "4     Effect of Cholecalciferol Plus Calcium on Fall...            2006   \n",
       "...                                                 ...             ...   \n",
       "2995  Toxic epidermal necrolysis. A review of 75 cas...            1975   \n",
       "2996  Complement component analysis in angiodema. Di...            1975   \n",
       "2997          Treatment of corns by injectable silicone            1975   \n",
       "2998  Hairy cutaneous malformations of palms and sol...            1975   \n",
       "2999  Immunocytochemical localization of cathepsin D...            1975   \n",
       "\n",
       "       prefix                           publisher subject  \n",
       "0     10.1001  American Medical Association (AMA)     NaN  \n",
       "1     10.1001  American Medical Association (AMA)     NaN  \n",
       "2     10.1001  American Medical Association (AMA)     NaN  \n",
       "3     10.1001  American Medical Association (AMA)     NaN  \n",
       "4     10.1001  American Medical Association (AMA)     NaN  \n",
       "...       ...                                 ...     ...  \n",
       "2995  10.1001  American Medical Association (AMA)     NaN  \n",
       "2996  10.1001  American Medical Association (AMA)     NaN  \n",
       "2997  10.1001  American Medical Association (AMA)     NaN  \n",
       "2998  10.1001  American Medical Association (AMA)     NaN  \n",
       "2999  10.1001  American Medical Association (AMA)     NaN  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "df_crossref=clean_crossref_data(json_object)\n",
    "df_crossref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking for Null values, there are some titles and published-print values missing, and unfortunately most of the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doi                   0\n",
       "type                  0\n",
       "title               211\n",
       "published-print     299\n",
       "prefix                0\n",
       "publisher             0\n",
       "subject            2689\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crossref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to clean all files in `crossref_data_raw` and save them in folder `crossref_data` in  JSON format, I am using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading crossref_data_raw/8.json.gz\n",
      "saved crossref_data/8_processed.json\n",
      "loading crossref_data_raw/24.json.gz\n",
      "saved crossref_data/24_processed.json\n",
      "loading crossref_data_raw/12.json.gz\n",
      "saved crossref_data/12_processed.json\n",
      "loading crossref_data_raw/1.json.gz\n",
      "saved crossref_data/1_processed.json\n",
      "loading crossref_data_raw/13.json.gz\n",
      "saved crossref_data/13_processed.json\n",
      "loading crossref_data_raw/0.json.gz\n",
      "saved crossref_data/0_processed.json\n",
      "loading crossref_data_raw/9.json.gz\n",
      "saved crossref_data/9_processed.json\n",
      "loading crossref_data_raw/25.json.gz\n",
      "saved crossref_data/25_processed.json\n",
      "loading crossref_data_raw/2.json.gz\n",
      "saved crossref_data/2_processed.json\n",
      "loading crossref_data_raw/11.json.gz\n",
      "saved crossref_data/11_processed.json\n",
      "loading crossref_data_raw/18.json.gz\n",
      "saved crossref_data/18_processed.json\n",
      "loading crossref_data_raw/27.json.gz\n",
      "saved crossref_data/27_processed.json\n",
      "loading crossref_data_raw/19.json.gz\n",
      "saved crossref_data/19_processed.json\n",
      "loading crossref_data_raw/26.json.gz\n",
      "saved crossref_data/26_processed.json\n",
      "loading crossref_data_raw/3.json.gz\n",
      "saved crossref_data/3_processed.json\n",
      "loading crossref_data_raw/10.json.gz\n",
      "saved crossref_data/10_processed.json\n",
      "loading crossref_data_raw/6.json.gz\n",
      "saved crossref_data/6_processed.json\n",
      "loading crossref_data_raw/15.json.gz\n",
      "saved crossref_data/15_processed.json\n",
      "loading crossref_data_raw/23.json.gz\n",
      "saved crossref_data/23_processed.json\n",
      "loading crossref_data_raw/32.json.gz\n",
      "saved crossref_data/32_processed.json\n",
      "loading crossref_data_raw/22.json.gz\n",
      "saved crossref_data/22_processed.json\n",
      "loading crossref_data_raw/7.json.gz\n",
      "saved crossref_data/7_processed.json\n",
      "loading crossref_data_raw/14.json.gz\n",
      "saved crossref_data/14_processed.json\n",
      "loading crossref_data_raw/20.json.gz\n",
      "saved crossref_data/20_processed.json\n",
      "loading crossref_data_raw/30.json.gz\n",
      "saved crossref_data/30_processed.json\n",
      "loading crossref_data_raw/29.json.gz\n",
      "saved crossref_data/29_processed.json\n",
      "loading crossref_data_raw/16.json.gz\n",
      "saved crossref_data/16_processed.json\n",
      "loading crossref_data_raw/5.json.gz\n",
      "saved crossref_data/5_processed.json\n",
      "loading crossref_data_raw/28.json.gz\n",
      "saved crossref_data/28_processed.json\n",
      "loading crossref_data_raw/17.json.gz\n",
      "saved crossref_data/17_processed.json\n",
      "loading crossref_data_raw/4.json.gz\n",
      "saved crossref_data/4_processed.json\n",
      "loading crossref_data_raw/31.json.gz\n",
      "saved crossref_data/31_processed.json\n",
      "loading crossref_data_raw/21.json.gz\n",
      "saved crossref_data/21_processed.json\n"
     ]
    }
   ],
   "source": [
    "path = 'crossref_data_raw/'\n",
    "\n",
    "filenames=glob.glob(os.path.join(path, '*.gz'))\n",
    "for filename in filenames:\n",
    "    print(\"loading {}\".format(filename))\n",
    "    \n",
    "    with gzip.open(filename) as file:\n",
    "        json_object = json.load(file)\n",
    "        file.close()\n",
    "        \n",
    "    df_crossref=clean_crossref_data(json_object)\n",
    "    \n",
    "    new_filename = filename.replace(\"_raw\",\"\").replace(\".json.gz\",\"_processed.json\")\n",
    "    \n",
    "    df_crossref.to_json(new_filename, orient='records', lines=True)\n",
    "    #df_crossref.to_parquet(new_filename, engine='pyarrow')\n",
    "    \n",
    "    print(\"saved {}\".format(new_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I uploaded these files manually to S3 bucket `s3://crossref-sample/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "First of all, there are two staging tables based on the two sources, Sci-Hub (table name `scihub_data`) and Crossref (table name `crossref_data`)\n",
    "\n",
    "I decided using a star schema with `downloads` as fact table with supporting dimension tables `time` and `users` which have the SciHub data as source.\n",
    "\n",
    "`downloads.timestamp` links to `time.timestamp`\n",
    "`downloads.user_id` links to `users.user_id`\n",
    "\n",
    "\n",
    "Table `articles` and `publishers` are dimension tables which have Crossref as data source.\n",
    "\n",
    "`downloads.doi` links to `articles.doi`\n",
    "\n",
    "As a normalization step I separated the publishers data from the articles to reduce redundancy.\n",
    "\n",
    "`articles.prefix` links to `publishers.prefix`\n",
    "\n",
    "\n",
    "Using this schema, you'll be able do explore all aspects of the downloads in a convenient way.\n",
    "\n",
    "![schema](Capstone_project_schema.png \"Schema\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "To pipeline the data into the the data model, the following steps are performed:\n",
    "    \n",
    "Read the data from the two S3 Buckets and stage it in the Redshift tables `scihub_data` and `crossref_data`\n",
    "\n",
    "Create the tables and insert the data into Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Let's assume we have a Redshift cluster with a database created with the neccessary authorizations to connect to S3 stored in `redshift.cfg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('redshift.cfg'))\n",
    "\n",
    "REGION_NAME            = config.get(\"AWS\",\"REGION_NAME\")\n",
    "\n",
    "#Redshift credentials\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "DWH_ENDPOINT           = config.get(\"DWH\",\"DWH_ENDPOINT\")\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\",\"DWH_IAM_ROLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### connect to Redshift database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://awsuser:Passw0rd@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n"
     ]
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT, DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### staging table scihub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS scihub_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS scihub_data (\n",
    "    timestamp TIMESTAMP NOT NULL, \n",
    "    doi varchar(256), \n",
    "    user_id varchar(256),\n",
    "    user_country varchar(256),\n",
    "    user_city varchar(256),\n",
    "    user_location varchar(256),\n",
    "    day INT8); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scihub_data_copy=\"\"\"\n",
    "COPY scihub_data\n",
    "FROM 's3://scihub-data/'\n",
    "CREDENTIALS 'aws_iam_role={}'\n",
    "FORMAT AS PARQUET;\n",
    "\"\"\".format(DWH_IAM_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql $scihub_data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### staging table crossref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS crossref_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS crossref_data (\n",
    "    doi varchar(256), \n",
    "    \"type\" varchar(256), \n",
    "    title varchar(512),\n",
    "    \"published-print\" INT,\n",
    "    prefix varchar(256),\n",
    "    publisher varchar(256),\n",
    "    subject varchar(256)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossref_data_copy=\"\"\"\n",
    "COPY crossref_data\n",
    "FROM 's3://crossref-sample/'\n",
    "CREDENTIALS 'aws_iam_role={}'\n",
    "REGION '{}'\n",
    "JSON AS 'auto';\n",
    "\"\"\".format(DWH_IAM_ROLE_NAME, REGION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql $crossref_data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### downloads table (fact table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS downloads\n",
    "    (\n",
    "    download_id INT IDENTITY (0,1),\n",
    "    timestamp TIMESTAMP NOT NULL,\n",
    "    doi VARCHAR(256) NOT NULL,\n",
    "    user_id VARCHAR(256) NOT NULL,\n",
    "    PRIMARY KEY(download_id)\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "8781017 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO downloads \n",
    "    (\"timestamp\",\n",
    "    \"doi\",\n",
    "    \"user_id\")\n",
    "SELECT \"timestamp\",\n",
    "       \"doi\",\n",
    "       \"user_id\"\n",
    "FROM scihub_data\n",
    "WHERE timestamp IS NOT NULL\n",
    "AND doi IS NOT NULL\n",
    "AND user_id IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### users table (dimension table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS users;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS users\n",
    "    (\n",
    "    user_id VARCHAR(256) NOT NULL,\n",
    "    user_country VARCHAR(256),\n",
    "    user_city VARCHAR(256),\n",
    "    user_location VARCHAR(256)\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1061153 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO users \n",
    "    (\"user_id\",\n",
    "    \"user_country\",\n",
    "    \"user_city\",\n",
    "    \"user_location\")\n",
    "SELECT DISTINCT \"user_id\",\n",
    "       \"user_country\",\n",
    "       \"user_city\",\n",
    "       \"user_location\"\n",
    "FROM scihub_data\n",
    "WHERE user_id IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### time table (dimension table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS time\n",
    "    (\n",
    "    timestamp TIMESTAMP,\n",
    "    year INT,\n",
    "    month INT,\n",
    "    week_of_year INT,\n",
    "    weekday INT,\n",
    "    day INT,\n",
    "    hour INT,\n",
    "    PRIMARY KEY(timestamp)\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "3817360 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO time \n",
    "    (\"timestamp\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"week_of_year\",\n",
    "    \"weekday\",\n",
    "    \"day\",\n",
    "    \"hour\")\n",
    "SELECT DISTINCT timestamp           AS timestamp,\n",
    "    EXTRACT(year FROM timestamp)    AS year,\n",
    "    EXTRACT(month FROM timestamp)   AS month,\n",
    "    EXTRACT(week FROM timestamp)    AS week_of_year,\n",
    "    EXTRACT(weekday FROM timestamp) AS weekday,\n",
    "    EXTRACT(day FROM timestamp)     AS day,\n",
    "    EXTRACT(hour FROM timestamp)    AS hour\n",
    "FROM scihub_data\n",
    "WHERE timestamp IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### articles table (dimension table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS articles\n",
    "    (\n",
    "    doi VARCHAR(256) NOT NULL,\n",
    "    title VARCHAR(512),\n",
    "    \"published-print\" INT,\n",
    "    prefix VARCHAR(256),\n",
    "    PRIMARY KEY(doi)\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "99000 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO articles \n",
    "    (\"doi\",\n",
    "    \"title\",\n",
    "    \"published-print\",\n",
    "    \"prefix\")\n",
    "SELECT DISTINCT \"doi\",\n",
    "       \"title\",\n",
    "       \"published-print\",\n",
    "       \"prefix\"\n",
    "FROM crossref_data\n",
    "WHERE doi IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### publishers table (dimension table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS publishers\n",
    "    (\n",
    "    prefix VARCHAR(256) NOT NULL,\n",
    "    publisher VARCHAR(256),\n",
    "    PRIMARY KEY(prefix)\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO publishers \n",
    "    (\"prefix\",\n",
    "    \"publisher\")\n",
    "SELECT DISTINCT \"prefix\",\n",
    "       \"publisher\"\n",
    "FROM crossref_data\n",
    "WHERE prefix IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data quality check 1: count number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8781017</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(8781017,)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM scihub_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>99000</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(99000,)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM crossref_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8781017</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(8781017,)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM downloads;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1061153</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1061153,)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM users;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3817360</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(3817360,)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>99000</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(99000,)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM articles;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(3,)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM publishers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### quality check 2: check if primary key is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM scihub_data WHERE timestamp IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM crossref_data WHERE doi IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM downloads WHERE download_id IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM users WHERE user_id IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM time WHERE timestamp IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM articles WHERE doi IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM publishers WHERE prefix IS NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table Name</th>\n",
       "      <th>Table Type</th>\n",
       "      <th>Field Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>download_id</td>\n",
       "      <td>INT</td>\n",
       "      <td>unique identifier for each download</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>date and time of article downloaded at SciHub</td>\n",
       "      <td>2015-12-01 00:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>doi</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>the DOI (digital object indentifier) of the do...</td>\n",
       "      <td>10.1109/SNPD.2007.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>user_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>the internal SciHub user identifier</td>\n",
       "      <td>56ed2c394b76d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>user_country</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>name of country of the SciHub user</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>user_city</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>name of city of the SciHub user</td>\n",
       "      <td>Medellín</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>user_location</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>pair of coordinates of location of the SciHub ...</td>\n",
       "      <td>6.2530408,-75.5645737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scihub_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>day</td>\n",
       "      <td>INT</td>\n",
       "      <td>used for partitioning the raw data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>crossref_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>date and time of article download at SciHub</td>\n",
       "      <td>2015-12-01 00:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>crossref_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>doi</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>the DOI (digital object indentifier) of an art...</td>\n",
       "      <td>10.1001/archneur.1977.00500210065012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>crossref_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>title</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>article title from Crossref</td>\n",
       "      <td>EEG Recognition of Aicardi's Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>crossref_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>published-print</td>\n",
       "      <td>INT</td>\n",
       "      <td>print publication year of article from Crossref</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>crossref_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>prefix</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>article publisher DOI prefix from Crossref</td>\n",
       "      <td>10.1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>crossref_data</td>\n",
       "      <td>Staging</td>\n",
       "      <td>publisher</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>publisher name from Crossref</td>\n",
       "      <td>Cambridge University Press (CUP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>downloads</td>\n",
       "      <td>Fact</td>\n",
       "      <td>download_id</td>\n",
       "      <td>INT</td>\n",
       "      <td>unique identifier for each download</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>downloads</td>\n",
       "      <td>Fact</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>date and time of article downloaded at SciHub</td>\n",
       "      <td>2015-12-01 00:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>downloads</td>\n",
       "      <td>Fact</td>\n",
       "      <td>doi</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>the DOI (digital object indentifier) of the do...</td>\n",
       "      <td>10.1109/SNPD.2007.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>downloads</td>\n",
       "      <td>Fact</td>\n",
       "      <td>user_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>the internal SciHub user identifier</td>\n",
       "      <td>56ed2c394b76d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>users</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>user_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>the internal SciHub user identifier</td>\n",
       "      <td>56ed2c394b76d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>users</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>user_country</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>name of country of the SciHub user</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>users</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>user_city</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>name of city of the SciHub user</td>\n",
       "      <td>Medellín</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>users</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>user_location</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>pair of coordinates of location of the SciHub ...</td>\n",
       "      <td>6.2530408,-75.5645737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>time</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>date and time of article download at SciHub</td>\n",
       "      <td>2015-12-01 00:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>time</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>year</td>\n",
       "      <td>INT</td>\n",
       "      <td>year of article download at SciHub</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>time</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>month</td>\n",
       "      <td>INT</td>\n",
       "      <td>month of article download at SciHub</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>time</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>week_of_year</td>\n",
       "      <td>INT</td>\n",
       "      <td>week of year of article download at SciHub</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>time</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>weekday</td>\n",
       "      <td>INT</td>\n",
       "      <td>weekday of article download at SciHub</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>time</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>day</td>\n",
       "      <td>INT</td>\n",
       "      <td>day of article download at SciHub</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>time</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>hour</td>\n",
       "      <td>INT</td>\n",
       "      <td>hour of article download at SciHub</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>articles</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>doi</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>the DOI (digital object indentifier) of an art...</td>\n",
       "      <td>10.1001/archneur.1977.00500210065012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>articles</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>title</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>article title from Crossref</td>\n",
       "      <td>EEG Recognition of Aicardi's Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>articles</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>published-print</td>\n",
       "      <td>INT</td>\n",
       "      <td>print publication year of article from Crossref</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>articles</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>prefix</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>article publisher DOI prefix from Crossref</td>\n",
       "      <td>10.1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>publishers</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>prefix</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>publisher DOI prefix from Crossref</td>\n",
       "      <td>10.1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>publishers</td>\n",
       "      <td>Dimension</td>\n",
       "      <td>publisher</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>publisher name from Crossref</td>\n",
       "      <td>Cambridge University Press (CUP)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Table Name Table Type       Field Name  Data Type  \\\n",
       "0     scihub_data    Staging      download_id        INT   \n",
       "1     scihub_data    Staging        timestamp  TIMESTAMP   \n",
       "2     scihub_data    Staging              doi    VARCHAR   \n",
       "3     scihub_data    Staging          user_id    VARCHAR   \n",
       "4     scihub_data    Staging     user_country    VARCHAR   \n",
       "5     scihub_data    Staging        user_city    VARCHAR   \n",
       "6     scihub_data    Staging    user_location    VARCHAR   \n",
       "7     scihub_data    Staging              day        INT   \n",
       "8   crossref_data    Staging        timestamp  TIMESTAMP   \n",
       "9   crossref_data    Staging              doi    VARCHAR   \n",
       "10  crossref_data    Staging            title    VARCHAR   \n",
       "11  crossref_data    Staging  published-print        INT   \n",
       "12  crossref_data    Staging           prefix    VARCHAR   \n",
       "13  crossref_data    Staging        publisher    VARCHAR   \n",
       "14      downloads       Fact      download_id        INT   \n",
       "15      downloads       Fact        timestamp  TIMESTAMP   \n",
       "16      downloads       Fact              doi    VARCHAR   \n",
       "17      downloads       Fact          user_id    VARCHAR   \n",
       "18          users  Dimension          user_id    VARCHAR   \n",
       "19          users  Dimension     user_country    VARCHAR   \n",
       "20          users  Dimension        user_city    VARCHAR   \n",
       "21          users  Dimension    user_location    VARCHAR   \n",
       "22           time  Dimension        timestamp  TIMESTAMP   \n",
       "23           time  Dimension             year        INT   \n",
       "24           time  Dimension            month        INT   \n",
       "25           time  Dimension     week_of_year        INT   \n",
       "26           time  Dimension          weekday        INT   \n",
       "27           time  Dimension              day        INT   \n",
       "28           time  Dimension             hour        INT   \n",
       "29       articles  Dimension              doi    VARCHAR   \n",
       "30       articles  Dimension            title    VARCHAR   \n",
       "31       articles  Dimension  published-print        INT   \n",
       "32       articles  Dimension           prefix    VARCHAR   \n",
       "33     publishers  Dimension           prefix    VARCHAR   \n",
       "34     publishers  Dimension        publisher    VARCHAR   \n",
       "\n",
       "                                          Description  \\\n",
       "0                 unique identifier for each download   \n",
       "1       date and time of article downloaded at SciHub   \n",
       "2   the DOI (digital object indentifier) of the do...   \n",
       "3                the internal SciHub user identifier    \n",
       "4                  name of country of the SciHub user   \n",
       "5                     name of city of the SciHub user   \n",
       "6   pair of coordinates of location of the SciHub ...   \n",
       "7                  used for partitioning the raw data   \n",
       "8         date and time of article download at SciHub   \n",
       "9   the DOI (digital object indentifier) of an art...   \n",
       "10                        article title from Crossref   \n",
       "11    print publication year of article from Crossref   \n",
       "12         article publisher DOI prefix from Crossref   \n",
       "13                       publisher name from Crossref   \n",
       "14                unique identifier for each download   \n",
       "15      date and time of article downloaded at SciHub   \n",
       "16  the DOI (digital object indentifier) of the do...   \n",
       "17               the internal SciHub user identifier    \n",
       "18               the internal SciHub user identifier    \n",
       "19                 name of country of the SciHub user   \n",
       "20                    name of city of the SciHub user   \n",
       "21  pair of coordinates of location of the SciHub ...   \n",
       "22        date and time of article download at SciHub   \n",
       "23                 year of article download at SciHub   \n",
       "24                month of article download at SciHub   \n",
       "25         week of year of article download at SciHub   \n",
       "26              weekday of article download at SciHub   \n",
       "27                  day of article download at SciHub   \n",
       "28                 hour of article download at SciHub   \n",
       "29  the DOI (digital object indentifier) of an art...   \n",
       "30                        article title from Crossref   \n",
       "31    print publication year of article from Crossref   \n",
       "32         article publisher DOI prefix from Crossref   \n",
       "33                 publisher DOI prefix from Crossref   \n",
       "34                       publisher name from Crossref   \n",
       "\n",
       "                                  Example  \n",
       "0                                       1  \n",
       "1                     2015-12-01 00:00:06  \n",
       "2                   10.1109/SNPD.2007.355  \n",
       "3                           56ed2c394b76d  \n",
       "4                                Colombia  \n",
       "5                                Medellín  \n",
       "6                   6.2530408,-75.5645737  \n",
       "7                                       1  \n",
       "8                     2015-12-01 00:00:06  \n",
       "9    10.1001/archneur.1977.00500210065012  \n",
       "10  EEG Recognition of Aicardi's Syndrome  \n",
       "11                                   1995  \n",
       "12                                10.1017  \n",
       "13       Cambridge University Press (CUP)  \n",
       "14                                      1  \n",
       "15                    2015-12-01 00:00:06  \n",
       "16                  10.1109/SNPD.2007.355  \n",
       "17                          56ed2c394b76d  \n",
       "18                          56ed2c394b76d  \n",
       "19                               Colombia  \n",
       "20                               Medellín  \n",
       "21                  6.2530408,-75.5645737  \n",
       "22                    2015-12-01 00:00:06  \n",
       "23                                   2015  \n",
       "24                                     12  \n",
       "25                                     49  \n",
       "26                                      2  \n",
       "27                                      1  \n",
       "28                                      0  \n",
       "29   10.1001/archneur.1977.00500210065012  \n",
       "30  EEG Recognition of Aicardi's Syndrome  \n",
       "31                                   1995  \n",
       "32                                10.1017  \n",
       "33                                10.1017  \n",
       "34       Cambridge University Press (CUP)  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dictionary=pd.read_table(\"data_dictionary.txt\")\n",
    "data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Clearly state the rationale for the choice of tools and technologies for the project.**\n",
    "\n",
    "Since they datasetes are very large, I choose to store the datasets for the staging tables in S3 because it can be picked up easily by Redshift. Redshift then allows all kinds of querying the data easily using SQL or an UI. Once the data is loaded you can perform analytical queries like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of articles which are found in both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4901</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(4901,)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT count(*)  \n",
    "FROM downloads d\n",
    "JOIN articles a\n",
    "ON d.doi = a.doi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the most popular titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>title_count</th>\n",
       "        <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>17</td>\n",
       "        <td>Syphilitic Pharyngitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>16</td>\n",
       "        <td>Psychosocial Risk Factors Associated With Cyberbullying Among Adolescents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>13</td>\n",
       "        <td>Serum Cholesterol, Blood Pressure, Cigarette Smoking, and Death From Coronary Heart Disease Overall Findings and Differences by Age for 316099 White Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>13</td>\n",
       "        <td>Disseminated Superficial Actinic Porokeratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>13</td>\n",
       "        <td>The Immunologic and Genetic Basis of Psoriasis</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(17, 'Syphilitic Pharyngitis'),\n",
       " (16, 'Psychosocial Risk Factors Associated With Cyberbullying Among Adolescents'),\n",
       " (13, 'Serum Cholesterol, Blood Pressure, Cigarette Smoking, and Death From Coronary Heart Disease Overall Findings and Differences by Age for 316099 White Men'),\n",
       " (13, 'Disseminated Superficial Actinic Porokeratosis'),\n",
       " (13, 'The Immunologic and Genetic Basis of Psoriasis')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT count(a.title) AS title_count,\n",
    "       a.title\n",
    "FROM downloads d\n",
    "JOIN articles a\n",
    "ON d.doi = a.doi\n",
    "GROUP BY a.title\n",
    "ORDER BY title_count DESC\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cities where most users are coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@dwhcluster.c27jojk0ergl.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>user_city_count</th>\n",
       "        <th>user_city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>57535</td>\n",
       "        <td>Tehran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19738</td>\n",
       "        <td>Moskva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>18297</td>\n",
       "        <td>Tiran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>15516</td>\n",
       "        <td>Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>15207</td>\n",
       "        <td>Lima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>15169</td>\n",
       "        <td>Tunis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>13945</td>\n",
       "        <td>Santiago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>12715</td>\n",
       "        <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10496</td>\n",
       "        <td>Athina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9487</td>\n",
       "        <td>Bengaluru</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(57535, 'Tehran'),\n",
       " (19738, 'Moskva'),\n",
       " (18297, 'Tiran'),\n",
       " (15516, 'Beijing'),\n",
       " (15207, 'Lima'),\n",
       " (15169, 'Tunis'),\n",
       " (13945, 'Santiago'),\n",
       " (12715, 'Chennai'),\n",
       " (10496, 'Athina'),\n",
       " (9487, 'Bengaluru')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count (user_city) AS user_city_count,\n",
    "user_city\n",
    "FROM users\n",
    "GROUP BY user_city\n",
    "ORDER BY user_city_count DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are many more options for queries such as:\n",
    "* what is the weekday of the most downloads\n",
    "* which subjects are requested most, are there differences by countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Propose how often the data should be updated and why.**\n",
    "\n",
    "Supposedly we would receive regular and up to date chunks of the server logs from Sci-Hub, e.g. monthly, we would also have to consequently update the Crossref dataset with the most recent articles to have the chance to match as many DOI as possible. There is an Crossref API that could be called, or we could use the latest Public Data File from Crossref available at `Academic Torrents` (currently, the most recent dataset was published in Jan 2021 https://academictorrents.com/details/e4287cb7619999709f6e9db5c359dda17e93d515)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Write a description of how you would approach the problem differently under the following scenarios:\n",
    "* **The data was increased by 100x.**\n",
    "    I would increase the size of the Redshift cluster to handle this data\n",
    "    \n",
    "* **The data populates a dashboard that must be updated on a daily basis by 7am every day.**\n",
    "    I would create a pipeline with Airflow that also includes data loading and the cleaning steps I performed, as well as any tasks to update the Redshift tables.\n",
    "    \n",
    "* **The database needed to be accessed by 100+ people.**\n",
    "Since I am using Redshift, I would just need to increase the size of the Redshift cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
